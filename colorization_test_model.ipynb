{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorization Test Model\n",
    "## This program will load an already-trained model, run it against a test set, and save individual test images\n",
    "## Output will be saved in ./Test_Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Reshape, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.saving import load_model\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_image_files(directory):\n",
    "    files = sorted(os.listdir(directory))\n",
    "    return [os.path.join(directory, f) for f in files if is_an_image_file(f)]\n",
    "\n",
    "def is_an_image_file(filename):\n",
    "    IMAGE_EXTENSIONS = ['.png', '.jpg', '.jpeg']\n",
    "    for ext in IMAGE_EXTENSIONS:\n",
    "        if ext in filename:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = cv2.imread(path[0])\n",
    "    \n",
    "    # Make sure all images are 256 x 256 by cropping them\n",
    "    r, c = img.shape[:2]\n",
    "    r_diff = (r - 256) // 2\n",
    "    c_diff = (c - 256) // 2\n",
    "    cropped = img[r_diff:256 + r_diff, c_diff:256 + c_diff] \n",
    "    return cropped\n",
    "\n",
    "def load_images(path, n_images=-1):\n",
    "    all_image_paths = list_image_files(path)\n",
    "    \n",
    "    if n_images < 0:\n",
    "        n_images = len(all_image_paths)\n",
    "    images_l, images_ab = [], []\n",
    "    \n",
    "    # Initialize a progress bar with max of n_images\n",
    "    pbar = tqdm_notebook(total = n_images, desc=\"Loading Images...\")\n",
    "    \n",
    "    for path in zip(all_image_paths):\n",
    "        img = load_image(path)\n",
    "        lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        lab_img = preprocess_image(lab_img)\n",
    "        \n",
    "        l = lab_img[:,:,0]\n",
    "        l = l[:,:,np.newaxis]\n",
    "        # Include all 3 channels, overwrite 1st channel with 0's\n",
    "        ab = lab_img[:,:,1:]\n",
    "\n",
    "        images_l.append(l)\n",
    "        images_ab.append(ab)\n",
    "\n",
    "        images_loaded = len(images_l)\n",
    "        \n",
    "        # Increase progress by one\n",
    "        pbar.update(1)\n",
    "        \n",
    "        if images_loaded > n_images - 1: \n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'l': np.array(images_l),\n",
    "        'ab': np.array(images_ab)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESHAPE = (256,256)\n",
    "\n",
    "def preprocess_image(cv_img):\n",
    "    img = (cv_img - 127.5) / 127.5\n",
    "    return img\n",
    "\n",
    "def deprocess_image(img):\n",
    "    img = (img * 127.5) + 127.5\n",
    "    return img.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(np_arr, path):\n",
    "    img = np_arr * 127.5 + 127.5\n",
    "    im = Image.fromarray(img)\n",
    "    im.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(H, W, k):\n",
    "    # Inputs: height and width of the input image\n",
    "    # Returns the model, which generates the AB channels\n",
    "\n",
    "    # Pix2pix adapted from \n",
    "    # https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py\n",
    "\n",
    "    def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "        \"\"\"Layers used during downsampling\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if bn:\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "        return d\n",
    "\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "        \"\"\"Layers used during upsampling\"\"\"\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "        u = BatchNormalization(momentum=0.8)(u)\n",
    "        u = Concatenate()([u, skip_input])\n",
    "        return u\n",
    "\n",
    "    gf = 64 # Number of filters in the first layer of G\n",
    "\n",
    "    noise_in = Input(shape=(100,))\n",
    "    condition_in = Input(shape=(H, W, 1))\n",
    "    \n",
    "    # pass noise through a FC layer to get it to the right size\n",
    "    noise = Dense(H * H)(noise_in)\n",
    "\n",
    "    # reshape to be the size of an image channel\n",
    "    noise = Reshape((H, H, 1))(noise)\n",
    "    \n",
    "    # stick the (somewhat modified) noise as the second channel after\n",
    "    # the gray input. Assuming new dimension of hid will be\n",
    "    # B x 256 x 256 x 2, where B is the batch size.\n",
    "#     d0 = Concatenate(axis=-1)([condition_in, noise])\n",
    "    d0 = condition_in # Don't need noise since it's being ignored anyway\n",
    "\n",
    "    # U-NET\n",
    "    # Downsampling\n",
    "    d1 = conv2d(d0, gf, bn=False)\n",
    "    d2 = conv2d(d1, gf*2)\n",
    "    d3 = conv2d(d2, gf*4)\n",
    "    d4 = conv2d(d3, gf*8)\n",
    "    d5 = conv2d(d4, gf*8)\n",
    "    d6 = conv2d(d5, gf*8)\n",
    "    d7 = conv2d(d6, gf*8)\n",
    "\n",
    "    # Upsampling\n",
    "    u1 = deconv2d(d7, d6, gf*8)\n",
    "    u2 = deconv2d(u1, d5, gf*8)\n",
    "    u3 = deconv2d(u2, d4, gf*8)\n",
    "    u4 = deconv2d(u3, d3, gf*4)\n",
    "    u5 = deconv2d(u4, d2, gf*2)\n",
    "    u6 = deconv2d(u5, d1, gf)\n",
    "\n",
    "    u7 = UpSampling2D(size=2)(u6)\n",
    "    \n",
    "    # Final 2-channel AB image with values between -1 and 1\n",
    "    img_out = Conv2D(2*k, kernel_size=4, strides=1, padding='same', activation='tanh', name='pred_ab')(u7)\n",
    "\n",
    "    # Make Model\n",
    "    model = Model(inputs=[noise_in, condition_in], outputs=img_out)\n",
    "    \n",
    "    # Show summary of layers\n",
    "    print(\"Generator Model:\")\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(H, W, k):\n",
    "    # Inputs: height and width of the input image\n",
    "    # Returns the model, which predicts real/fake\n",
    "    # over a set of spatial regions (i.e., predicts a matrix instead of a scalar).\n",
    "\n",
    "    # Pix2pix adapted from \n",
    "    # https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py\n",
    "\n",
    "    def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if bn:\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "        return d\n",
    "\n",
    "    # Number of filters in the first layer of D\n",
    "    df = 64\n",
    "\n",
    "    img_in = Input(shape=(H, W, 2*k)) # AB channels\n",
    "    condition_in = Input(shape=(H, W, 1)) # L channel\n",
    "    \n",
    "    # Concat the L and AB channels\n",
    "    concat_imgs = Concatenate()([condition_in, img_in])\n",
    "\n",
    "    d1 = d_layer(concat_imgs, df, bn=False)\n",
    "    d2 = d_layer(d1, df*2)\n",
    "    d3 = d_layer(d2, df*4)\n",
    "    d4 = d_layer(d3, df*8)\n",
    "\n",
    "    # validity map is a one-channel matrix 1/16 the size of the input (halved 4 times).\n",
    "    # Each number predicts whether a region of the input is real/fake.\n",
    "    validity = Conv2D(1*k, kernel_size=4, strides=1, padding='same', name='pred_valid')(d4)\n",
    "\n",
    "    # Build Model\n",
    "    model = Model(inputs=[img_in, condition_in], outputs=validity)\n",
    "\n",
    "    # Show summary of layers\n",
    "    print(\"Disciminator Model:\")\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_k_diff(y_true, y_pred):\n",
    "    # Shape: (Batch, H, W, k, 2)\n",
    "    y_true = K.reshape(y_true, (-1, H, W, k, 2))\n",
    "    y_pred = K.reshape(y_pred, (-1, H, W, k, 2))\n",
    "\n",
    "    print(\"true:\", y_true.shape)\n",
    "    print(\"pred:\", y_pred.shape)\n",
    "\n",
    "    diff = y_true - y_pred\n",
    "    diff = K.abs(diff)\n",
    "    diff = K.mean(diff, axis=(1, 2, 4)) # mean of (H, W, 2) leaves (B, k)\n",
    "    \n",
    "    loss_metric = diff\n",
    "\n",
    "    min_for_each_batch = K.min(loss_metric, axis=1)\n",
    "    return K.sum(min_for_each_batch) #* .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def generate_noise(n_samples, noise_dim):\n",
    "    X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "trained_model_name = \"lsun_colorization_full_model\"\n",
    "k = 5\n",
    "\n",
    "# Testing parameters\n",
    "num_test_imgs = 100 \n",
    "random_select_gt_or_colorzed = True\n",
    "\n",
    "# dataset = 'new_circles/'\n",
    "# dataset = '../Colorization_GAN/circle_pairs/'\n",
    "dataset = 'lsun/'\n",
    "# dataset = 'places2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where model is located\n",
    "saved_model_location = \"Output/\" + trained_model_name + \"/GAN_Weights_Epoch_100.h5\"\n",
    "\n",
    "# Create folder to store output\n",
    "generic_output_folder = \"Test_Output/\"\n",
    "new_output_folder = trained_model_name + \"/\"\n",
    "save_path = generic_output_folder + new_output_folder\n",
    "if random_select_gt_or_colorzed:\n",
    "    save_path += \"random_colorized_or_ground_truth/\"\n",
    "else:\n",
    "    save_path += \"all_predictions/\"\n",
    "\n",
    "# Ensure output can save in desired location\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a3747b26e34ebca4552be02adf58bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Loading Images...', style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===================================\n",
    "# COULD NOT HANDLE LARGE TRAINING SET\n",
    "# ===================================\n",
    "\n",
    "# Get training images\n",
    "# Load dataset, convert to LAB, normalize to range [-1, 1]\n",
    "data = load_images(dataset + 'test', num_test_imgs)\n",
    "\n",
    "# Only want l channel\n",
    "l_channel_imgs, ab_channel_imgs = data['l'], data['ab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Disciminator Model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 256, 256, 10) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 256, 11) 0           input_2[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 11328       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 128)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 128)  512         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 256)  524544      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 256)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 256)  1024        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 512)  2097664     batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 512)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 512)  2048        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pred_valid (Conv2D)             (None, 16, 16, 5)    40965       batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 2,809,285\n",
      "Trainable params: 2,807,493\n",
      "Non-trainable params: 1,792\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /home/drew/anaconda3/envs/tf-gpu-1.14/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "Generator Model:\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 1088        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 128)  131200      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 64, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 256)  524544      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 32, 32, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 512)  2097664     batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 512)  2048        leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 512)    4194816     batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 512)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 512)    2048        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 512)    4194816     batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 4, 4, 512)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4, 4, 512)    2048        leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 2, 2, 512)    4194816     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 2, 2, 512)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2, 2, 512)    2048        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 4, 4, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 512)    4194816     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 4, 512)    2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 4, 1024)   0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 1024)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 512)    8389120     up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 512)    2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 1024)   0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 1024) 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 512)  8389120     up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 1024) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 256)  4194560     up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 256)  1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 512)  0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 512)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 128)  1048704     up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 256 0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 64) 262208      up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 128 0           batch_normalization_15[0][0]     \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 128 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pred_ab (Conv2D)                (None, 256, 256, 10) 20490       up_sampling2d_7[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 41,855,626\n",
      "Trainable params: 41,846,794\n",
      "Non-trainable params: 8,832\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_ab: (?, 256, 256, 10)\n",
      "gan_condition_in: (?, 256, 256, 1)\n",
      "true: (?, 256, 256, 5, 2)\n",
      "pred: (?, 256, 256, 5, 2)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gen_model (Model)               (None, 256, 256, 10) 41855626    input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "discrim_model (Model)           (None, 16, 16, 5)    2809285     gen_model[1][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 44,664,911\n",
      "Trainable params: 41,846,794\n",
      "Non-trainable params: 2,818,117\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GAN creation\n",
    "H = W = 256\n",
    "\n",
    "# Discriminator loss - MSE seems to produce better results\n",
    "#discrim_loss = 'binary_crossentropy'\n",
    "discrim_loss = 'mse'\n",
    "\n",
    "# 1. Discriminator\n",
    "# Calculate output shape of D (PatchGAN)\n",
    "patch = H // 2**4 # Input size gets cut in half 4 times\n",
    "discriminator = get_discriminator(H, W, k)\n",
    "discriminator.name = 'discrim_model' # Need a name for the loss dictionary below\n",
    "discriminator.compile(optimizer=Adam(2e-4, 0.5), loss=discrim_loss, metrics=['accuracy'])\n",
    "discriminator.trainable = False # For the combined model we will only train the generator\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Generator\n",
    "generator = get_generator(H, W, k)\n",
    "generator.name = 'gen_model' # Need a name for the loss dictionary below\n",
    "\n",
    "# 3. GAN\n",
    "gan_noise_in = Input(shape=(100,))\n",
    "gan_condition_in = Input(shape=(H, W, 1))\n",
    "\n",
    "# By conditioning on L generate a fake version of AB\n",
    "fake_AB = generator([gan_noise_in, gan_condition_in])\n",
    "\n",
    "# Discriminator determines validity of AB images / L pairs\n",
    "print(\"fake_ab:\", fake_AB.shape)\n",
    "\n",
    "print(\"gan_condition_in:\", gan_condition_in.shape)\n",
    "\n",
    "valid = discriminator([fake_AB, gan_condition_in])\n",
    "\n",
    "losses = {'gen_model': min_k_diff, # used to be 'gen_loss'\n",
    "          'discrim_model': discrim_loss}\n",
    "loss_weights = {'gen_model': 100.0, 'discrim_model': 1.0}\n",
    "\n",
    "gan = Model(inputs=[gan_noise_in, gan_condition_in], outputs=[fake_AB, valid])\n",
    "gan.compile(optimizer=Adam(2e-4, 0.5), loss=losses, loss_weights=loss_weights)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output/lsun_colorization_full_model/GAN_Weights_Epoch_100.h5\n"
     ]
    }
   ],
   "source": [
    "print(saved_model_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the weights\n",
    "discriminator.load_weights('Output/lsun_colorization_full_model/Discriminator_Weights_Epoch_100.h5')\n",
    "gan.load_weights('Output/lsun_colorization_full_model/GAN_Weights_Epoch_100.h5')\n",
    "\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for 100 images complete!\n"
     ]
    }
   ],
   "source": [
    "noise = generate_noise(num_test_imgs, 100)\n",
    "\n",
    "# colorized_predictions is [num_test_imgs, k]\n",
    "colorized_predictions = generator.predict([noise, l_channel_imgs])\n",
    "\n",
    "print(\"Predictions for\", len(colorized_predictions), \"images complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rgb_img(l, ab, i, filename):\n",
    "    # Make sure ab is the right type, generated imgs change to float32\n",
    "    ab = ab.astype(np.float64)\n",
    "    \n",
    "    # Merge\n",
    "    merged = cv2.merge((l, ab))\n",
    "    \n",
    "    # Get between 0, 255\n",
    "    deprocessed = deprocess_image(merged)\n",
    "    \n",
    "    # Change to BGR (Curse you CV2!!!)\n",
    "    rgb = cv2.cvtColor(deprocessed, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Save\n",
    "    cv2.imwrite(save_path + filename, rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging, deprocessing, converting to RGB, and saving images\n",
      "-- 25 completed\n",
      "-- 50 completed\n",
      "-- 75 completed\n",
      "-- 100 completed\n",
      "DONE!\n",
      "\n",
      "Breakdown of Ground Truth vs. Colorized Selected:\n",
      "Ground Truth: 49 -- 49.0%\n",
      "Colorized: 51 -- 51.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging, deprocessing, converting to RGB, and saving images\")\n",
    "\n",
    "num_ground_truth_selected = 0\n",
    "\n",
    "# Loop through images that were colorized\n",
    "for i, img in enumerate(colorized_predictions):\n",
    "    filename = str(i+1).zfill(len(str(num_test_imgs)))\n",
    "\n",
    "    # For each img, use either ground truth or random colorized prediction\n",
    "    if random_select_gt_or_colorzed:\n",
    "        # Determine whether to use ground truth or prediction\n",
    "        use_ground_truth = random.choice([True, False])\n",
    "        \n",
    "        if use_ground_truth:\n",
    "            num_ground_truth_selected += 1\n",
    "            filename += \"_Ground_Truth.png\"\n",
    "            save_rgb_img(l_channel_imgs[i], ab_channel_imgs[i], i, filename)\n",
    "        else:\n",
    "            prediction_i = random.randint(0,k-1)\n",
    "            filename += \"_Colorized_.png\"\n",
    "            prediction = img[:,:,2*prediction_i:2*prediction_i+2]\n",
    "            save_rgb_img(l_channel_imgs[i], prediction, i, filename)\n",
    "    else:\n",
    "        # Loop through predictions\n",
    "        for j in range(k):\n",
    "            prediction = img[:,:,2*j:2*j+2]\n",
    "            save_rgb_img(l_channel_imgs[i], prediction, i, filename + \"-\" + str(j+1) + \".png\")\n",
    "            \n",
    "    if (i + 1) % 25 == 0:\n",
    "        print(\"--\", i+1, \"completed\")\n",
    "        \n",
    "print(\"DONE!\")\n",
    "\n",
    "if random_select_gt_or_colorzed:\n",
    "    print(\"\\nBreakdown of Ground Truth vs. Colorized Selected:\")\n",
    "    print(\"Ground Truth:\", num_ground_truth_selected, \"--\", str(100 * num_ground_truth_selected / num_test_imgs) + \"%\")\n",
    "    print(\"Colorized:\", num_test_imgs - num_ground_truth_selected, \"--\", str(100 * (num_test_imgs - num_ground_truth_selected) / num_test_imgs) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 0 =====\n",
      "0 -611.6212\n",
      "1 -537.7493\n",
      "2 -454.92267\n",
      "3 -721.1657\n",
      "4 -49.701584\n",
      "MIN: 3\n",
      "===== 1 =====\n",
      "0 -180.33813\n",
      "1 -125.81885\n",
      "2 -88.437256\n",
      "3 -325.2655\n",
      "4 321.8932\n",
      "MIN: 3\n",
      "===== 2 =====\n",
      "0 -1833.7739\n",
      "1 -1770.6782\n",
      "2 -1753.2402\n",
      "3 -1959.8857\n",
      "4 -1475.3164\n",
      "MIN: 3\n",
      "===== 3 =====\n",
      "0 796.3767\n",
      "1 860.2129\n",
      "2 891.1913\n",
      "3 710.1904\n",
      "4 1177.862\n",
      "MIN: 3\n",
      "===== 4 =====\n",
      "0 -1400.9674\n",
      "1 -1340.4893\n",
      "2 -1281.1377\n",
      "3 -1522.4576\n",
      "4 -914.71814\n",
      "MIN: 3\n",
      "===== 5 =====\n",
      "0 4574.956\n",
      "1 4645.1436\n",
      "2 4688.954\n",
      "3 4457.4\n",
      "4 5044.89\n",
      "MIN: 3\n",
      "===== 6 =====\n",
      "0 -902.0542\n",
      "1 -839.8125\n",
      "2 -784.7599\n",
      "3 -979.7953\n",
      "4 -472.80008\n",
      "MIN: 3\n",
      "===== 7 =====\n",
      "0 683.6513\n",
      "1 742.59766\n",
      "2 847.90283\n",
      "3 590.50195\n",
      "4 1196.9446\n",
      "MIN: 3\n",
      "===== 8 =====\n",
      "0 256.5343\n",
      "1 312.2461\n",
      "2 315.2163\n",
      "3 185.22107\n",
      "4 539.9988\n",
      "MIN: 3\n",
      "===== 9 =====\n",
      "0 1511.5364\n",
      "1 1570.8456\n",
      "2 1611.3647\n",
      "3 1427.2673\n",
      "4 1924.6301\n",
      "MIN: 3\n",
      "===== 10 =====\n",
      "0 -447.3651\n",
      "1 -386.97827\n",
      "2 -340.51184\n",
      "3 -506.068\n",
      "4 -83.01221\n",
      "MIN: 3\n",
      "===== 11 =====\n",
      "0 -1074.8641\n",
      "1 -1013.9446\n",
      "2 -963.33936\n",
      "3 -1161.7313\n",
      "4 -711.56226\n",
      "MIN: 3\n",
      "===== 12 =====\n",
      "0 724.86926\n",
      "1 782.20776\n",
      "2 810.3469\n",
      "3 645.6749\n",
      "4 1049.5693\n",
      "MIN: 3\n",
      "===== 13 =====\n",
      "0 1532.3771\n",
      "1 1564.5442\n",
      "2 1615.0343\n",
      "3 1458.571\n",
      "4 1802.7849\n",
      "MIN: 3\n",
      "===== 14 =====\n",
      "0 2767.211\n",
      "1 2818.6304\n",
      "2 2903.0764\n",
      "3 2663.3098\n",
      "4 3237.8018\n",
      "MIN: 3\n",
      "===== 15 =====\n",
      "0 602.75195\n",
      "1 677.8867\n",
      "2 616.9668\n",
      "3 410.3418\n",
      "4 1013.79395\n",
      "MIN: 3\n",
      "===== 16 =====\n",
      "0 1758.8345\n",
      "1 1828.5505\n",
      "2 1870.8591\n",
      "3 1592.6826\n",
      "4 2313.4736\n",
      "MIN: 3\n",
      "===== 17 =====\n",
      "0 49.478714\n",
      "1 118.46466\n",
      "2 151.289\n",
      "3 -10.113815\n",
      "4 448.21808\n",
      "MIN: 3\n",
      "===== 18 =====\n",
      "0 6056.942\n",
      "1 6093.3193\n",
      "2 6087.1367\n",
      "3 5969.6367\n",
      "4 6255.4746\n",
      "MIN: 3\n",
      "===== 19 =====\n",
      "0 1575.395\n",
      "1 1632.749\n",
      "2 1692.1836\n",
      "3 1513.3513\n",
      "4 1960.1133\n",
      "MIN: 3\n",
      "===== 20 =====\n",
      "0 -2218.2642\n",
      "1 -2151.429\n",
      "2 -2090.886\n",
      "3 -2300.7024\n",
      "4 -1766.2471\n",
      "MIN: 3\n",
      "===== 21 =====\n",
      "0 -1220.7994\n",
      "1 -1157.102\n",
      "2 -1089.593\n",
      "3 -1341.346\n",
      "4 -673.6848\n",
      "MIN: 3\n",
      "===== 22 =====\n",
      "0 3916.4714\n",
      "1 3970.5125\n",
      "2 4016.3865\n",
      "3 3851.7744\n",
      "4 4266.0625\n",
      "MIN: 3\n",
      "===== 23 =====\n",
      "0 2510.9487\n",
      "1 2565.8918\n",
      "2 2642.7131\n",
      "3 2438.4949\n",
      "4 2951.3098\n",
      "MIN: 3\n",
      "===== 24 =====\n",
      "0 1677.1638\n",
      "1 1731.3429\n",
      "2 1805.4465\n",
      "3 1610.2366\n",
      "4 2061.356\n",
      "MIN: 3\n",
      "===== 25 =====\n",
      "0 -2219.4214\n",
      "1 -2161.838\n",
      "2 -2097.397\n",
      "3 -2274.8105\n",
      "4 -1857.7281\n",
      "MIN: 3\n",
      "===== 26 =====\n",
      "0 -392.38586\n",
      "1 -329.47107\n",
      "2 -263.51233\n",
      "3 -473.45593\n",
      "4 37.723267\n",
      "MIN: 3\n",
      "===== 27 =====\n",
      "0 2475.3706\n",
      "1 2544.4065\n",
      "2 2644.9438\n",
      "3 2386.719\n",
      "4 3007.9548\n",
      "MIN: 3\n",
      "===== 28 =====\n",
      "0 -47.210236\n",
      "1 37.226135\n",
      "2 104.26932\n",
      "3 -179.45059\n",
      "4 599.1133\n",
      "MIN: 3\n",
      "===== 29 =====\n",
      "0 -1365.5409\n",
      "1 -1306.5642\n",
      "2 -1351.3357\n",
      "3 -1442.1255\n",
      "4 -1197.4373\n",
      "MIN: 3\n",
      "===== 30 =====\n",
      "0 1703.4208\n",
      "1 1758.9119\n",
      "2 1856.7456\n",
      "3 1583.6118\n",
      "4 2197.5073\n",
      "MIN: 3\n",
      "===== 31 =====\n",
      "0 405.0916\n",
      "1 466.74487\n",
      "2 547.46387\n",
      "3 326.14444\n",
      "4 891.18097\n",
      "MIN: 3\n",
      "===== 32 =====\n",
      "0 -2791.565\n",
      "1 -2729.2578\n",
      "2 -2669.0864\n",
      "3 -2859.6836\n",
      "4 -2387.0366\n",
      "MIN: 3\n",
      "===== 33 =====\n",
      "0 200.48584\n",
      "1 283.8169\n",
      "2 310.02112\n",
      "3 98.02881\n",
      "4 675.4019\n",
      "MIN: 3\n",
      "===== 34 =====\n",
      "0 4930.75\n",
      "1 4993.797\n",
      "2 5061.0986\n",
      "3 4821.7246\n",
      "4 5442.9873\n",
      "MIN: 3\n",
      "===== 35 =====\n",
      "0 -977.34265\n",
      "1 -911.0951\n",
      "2 -840.30084\n",
      "3 -1061.8497\n",
      "4 -479.88983\n",
      "MIN: 3\n",
      "===== 36 =====\n",
      "0 -1606.0908\n",
      "1 -1514.7124\n",
      "2 -1479.9514\n",
      "3 -1807.3914\n",
      "4 -953.34595\n",
      "MIN: 3\n",
      "===== 37 =====\n",
      "0 8365.172\n",
      "1 8447.069\n",
      "2 8526.992\n",
      "3 8118.175\n",
      "4 9195.856\n",
      "MIN: 3\n",
      "===== 38 =====\n",
      "0 1591.5271\n",
      "1 1637.2867\n",
      "2 1624.696\n",
      "3 1460.4773\n",
      "4 1859.4963\n",
      "MIN: 3\n",
      "===== 39 =====\n",
      "0 1715.1353\n",
      "1 1788.1497\n",
      "2 1750.73\n",
      "3 1568.0625\n",
      "4 2077.3584\n",
      "MIN: 3\n",
      "===== 40 =====\n",
      "0 -996.2043\n",
      "1 -917.1045\n",
      "2 -846.1305\n",
      "3 -1086.345\n",
      "4 -469.46478\n",
      "MIN: 3\n",
      "===== 41 =====\n",
      "0 -2095.4104\n",
      "1 -2026.843\n",
      "2 -2037.7609\n",
      "3 -2196.5664\n",
      "4 -1730.489\n",
      "MIN: 3\n",
      "===== 42 =====\n",
      "0 -572.72876\n",
      "1 -509.25256\n",
      "2 -524.17053\n",
      "3 -696.55945\n",
      "4 -181.72815\n",
      "MIN: 3\n",
      "===== 43 =====\n",
      "0 -421.9807\n",
      "1 -366.2257\n",
      "2 -277.0537\n",
      "3 -501.71753\n",
      "4 37.072998\n",
      "MIN: 3\n",
      "===== 44 =====\n",
      "0 8819.276\n",
      "1 8885.729\n",
      "2 8884.519\n",
      "3 8674.462\n",
      "4 9281.6455\n",
      "MIN: 3\n",
      "===== 45 =====\n",
      "0 670.53516\n",
      "1 746.4972\n",
      "2 812.6625\n",
      "3 582.12024\n",
      "4 1185.928\n",
      "MIN: 3\n",
      "===== 46 =====\n",
      "0 -202.73192\n",
      "1 -155.00238\n",
      "2 -124.03265\n",
      "3 -280.77728\n",
      "4 128.86331\n",
      "MIN: 3\n",
      "===== 47 =====\n",
      "0 3262.0645\n",
      "1 3330.421\n",
      "2 3344.8257\n",
      "3 3167.3784\n",
      "4 3618.9375\n",
      "MIN: 3\n",
      "===== 48 =====\n",
      "0 -2444.692\n",
      "1 -2380.0146\n",
      "2 -2284.9714\n",
      "3 -2542.026\n",
      "4 -1895.8286\n",
      "MIN: 3\n",
      "===== 49 =====\n",
      "0 821.2998\n",
      "1 879.22986\n",
      "2 922.83887\n",
      "3 729.4497\n",
      "4 1229.7368\n",
      "MIN: 3\n",
      "===== 50 =====\n",
      "0 2037.009\n",
      "1 2094.845\n",
      "2 2169.213\n",
      "3 1975.137\n",
      "4 2457.4663\n",
      "MIN: 3\n",
      "===== 51 =====\n",
      "0 -1677.1602\n",
      "1 -1611.775\n",
      "2 -1535.2026\n",
      "3 -1759.8938\n",
      "4 -1192.242\n",
      "MIN: 3\n",
      "===== 52 =====\n",
      "0 -1112.3074\n",
      "1 -1034.7758\n",
      "2 -932.618\n",
      "3 -1231.6736\n",
      "4 -447.05386\n",
      "MIN: 3\n",
      "===== 53 =====\n",
      "0 -275.46307\n",
      "1 -199.36456\n",
      "2 -176.11273\n",
      "3 -449.2054\n",
      "4 309.16718\n",
      "MIN: 3\n",
      "===== 54 =====\n",
      "0 -186.57559\n",
      "1 -118.79991\n",
      "2 -28.017334\n",
      "3 -298.92795\n",
      "4 367.2514\n",
      "MIN: 3\n",
      "===== 55 =====\n",
      "0 -2500.6777\n",
      "1 -2441.2515\n",
      "2 -2391.4019\n",
      "3 -2599.0444\n",
      "4 -2050.7952\n",
      "MIN: 3\n",
      "===== 56 =====\n",
      "0 3688.6255\n",
      "1 3733.605\n",
      "2 3752.7527\n",
      "3 3596.1829\n",
      "4 3997.8926\n",
      "MIN: 3\n",
      "===== 57 =====\n",
      "0 208.81549\n",
      "1 263.84412\n",
      "2 263.55237\n",
      "3 141.32776\n",
      "4 447.53644\n",
      "MIN: 3\n",
      "===== 58 =====\n",
      "0 5980.4326\n",
      "1 6038.0483\n",
      "2 6062.597\n",
      "3 5887.953\n",
      "4 6337.482\n",
      "MIN: 3\n",
      "===== 59 =====\n",
      "0 -1.8324585\n",
      "1 69.69888\n",
      "2 141.14175\n",
      "3 -111.66107\n",
      "4 522.37427\n",
      "MIN: 3\n",
      "===== 60 =====\n",
      "0 580.37366\n",
      "1 636.59863\n",
      "2 711.8971\n",
      "3 523.90906\n",
      "4 965.261\n",
      "MIN: 3\n",
      "===== 61 =====\n",
      "0 -2033.8215\n",
      "1 -1983.269\n",
      "2 -1959.5972\n",
      "3 -2085.5627\n",
      "4 -1803.3557\n",
      "MIN: 3\n",
      "===== 62 =====\n",
      "0 -1179.0155\n",
      "1 -1113.51\n",
      "2 -1116.7211\n",
      "3 -1333.7872\n",
      "4 -755.4324\n",
      "MIN: 3\n",
      "===== 63 =====\n",
      "0 1101.3174\n",
      "1 1169.1504\n",
      "2 1242.1031\n",
      "3 967.121\n",
      "4 1721.2141\n",
      "MIN: 3\n",
      "===== 64 =====\n",
      "0 4323.836\n",
      "1 4407.2744\n",
      "2 4443.5137\n",
      "3 4209.9404\n",
      "4 4850.991\n",
      "MIN: 3\n",
      "===== 65 =====\n",
      "0 -1525.2058\n",
      "1 -1466.9899\n",
      "2 -1410.6273\n",
      "3 -1594.3552\n",
      "4 -1144.1746\n",
      "MIN: 3\n",
      "===== 66 =====\n",
      "0 -2107.4785\n",
      "1 -2052.598\n",
      "2 -1979.4956\n",
      "3 -2180.2632\n",
      "4 -1696.5815\n",
      "MIN: 3\n",
      "===== 67 =====\n",
      "0 1929.7375\n",
      "1 1995.8999\n",
      "2 2044.1208\n",
      "3 1797.1724\n",
      "4 2454.871\n",
      "MIN: 3\n",
      "===== 68 =====\n",
      "0 -362.40582\n",
      "1 -296.54358\n",
      "2 -301.71088\n",
      "3 -420.35883\n",
      "4 -113.05884\n",
      "MIN: 3\n",
      "===== 69 =====\n",
      "0 -3060.642\n",
      "1 -3002.933\n",
      "2 -2928.4253\n",
      "3 -3137.3413\n",
      "4 -2597.9832\n",
      "MIN: 3\n",
      "===== 70 =====\n",
      "0 2992.8105\n",
      "1 3054.2761\n",
      "2 3120.041\n",
      "3 2921.2085\n",
      "4 3410.2192\n",
      "MIN: 3\n",
      "===== 71 =====\n",
      "0 -614.11206\n",
      "1 -552.3446\n",
      "2 -443.0173\n",
      "3 -703.5139\n",
      "4 -66.277405\n",
      "MIN: 3\n",
      "===== 72 =====\n",
      "0 692.36365\n",
      "1 760.4181\n",
      "2 828.44104\n",
      "3 568.94745\n",
      "4 1228.2809\n",
      "MIN: 3\n",
      "===== 73 =====\n",
      "0 -55.814636\n",
      "1 5.9796753\n",
      "2 65.246826\n",
      "3 -165.08524\n",
      "4 439.30664\n",
      "MIN: 3\n",
      "===== 74 =====\n",
      "0 -3111.275\n",
      "1 -3054.9197\n",
      "2 -2991.4087\n",
      "3 -3195.1396\n",
      "4 -2703.33\n",
      "MIN: 3\n",
      "===== 75 =====\n",
      "0 -753.4615\n",
      "1 -694.4365\n",
      "2 -612.3829\n",
      "3 -859.73267\n",
      "4 -265.9488\n",
      "MIN: 3\n",
      "===== 76 =====\n",
      "0 -859.4253\n",
      "1 -799.879\n",
      "2 -710.8618\n",
      "3 -932.45184\n",
      "4 -416.156\n",
      "MIN: 3\n",
      "===== 77 =====\n",
      "0 2966.0164\n",
      "1 3021.0935\n",
      "2 3055.6301\n",
      "3 2876.4978\n",
      "4 3317.4473\n",
      "MIN: 3\n",
      "===== 78 =====\n",
      "0 367.91107\n",
      "1 444.4162\n",
      "2 470.24493\n",
      "3 274.89557\n",
      "4 811.245\n",
      "MIN: 3\n",
      "===== 79 =====\n",
      "0 7248.6465\n",
      "1 7325.188\n",
      "2 7389.3906\n",
      "3 7128.157\n",
      "4 7850.219\n",
      "MIN: 3\n",
      "===== 80 =====\n",
      "0 71.11505\n",
      "1 150.5744\n",
      "2 184.1789\n",
      "3 -8.049988\n",
      "4 509.85492\n",
      "MIN: 3\n",
      "===== 81 =====\n",
      "0 -757.034\n",
      "1 -703.7499\n",
      "2 -669.9061\n",
      "3 -826.8847\n",
      "4 -454.0133\n",
      "MIN: 3\n",
      "===== 82 =====\n",
      "0 -39.032593\n",
      "1 23.878906\n",
      "2 57.57715\n",
      "3 -101.32416\n",
      "4 312.7572\n",
      "MIN: 3\n",
      "===== 83 =====\n",
      "0 -421.71216\n",
      "1 -353.30347\n",
      "2 -301.92224\n",
      "3 -580.0386\n",
      "4 181.52979\n",
      "MIN: 3\n",
      "===== 84 =====\n",
      "0 900.98584\n",
      "1 960.57715\n",
      "2 1031.6085\n",
      "3 850.756\n",
      "4 1265.8018\n",
      "MIN: 3\n",
      "===== 85 =====\n",
      "0 7644.599\n",
      "1 7656.9673\n",
      "2 7739.4814\n",
      "3 7549.7617\n",
      "4 7924.6226\n",
      "MIN: 3\n",
      "===== 86 =====\n",
      "0 -581.6236\n",
      "1 -530.3021\n",
      "2 -456.08643\n",
      "3 -660.994\n",
      "4 -162.28888\n",
      "MIN: 3\n",
      "===== 87 =====\n",
      "0 -888.18536\n",
      "1 -830.0339\n",
      "2 -786.0581\n",
      "3 -959.5321\n",
      "4 -517.848\n",
      "MIN: 3\n",
      "===== 88 =====\n",
      "0 966.0221\n",
      "1 1033.8359\n",
      "2 1052.391\n",
      "3 882.7742\n",
      "4 1352.3606\n",
      "MIN: 3\n",
      "===== 89 =====\n",
      "0 -452.46252\n",
      "1 -370.2341\n",
      "2 -293.30444\n",
      "3 -564.9721\n",
      "4 156.88803\n",
      "MIN: 3\n",
      "===== 90 =====\n",
      "0 -198.35425\n",
      "1 -147.54248\n",
      "2 -151.42224\n",
      "3 -297.26636\n",
      "4 77.03381\n",
      "MIN: 3\n",
      "===== 91 =====\n",
      "0 2681.2104\n",
      "1 2738.4229\n",
      "2 2760.5134\n",
      "3 2606.7354\n",
      "4 3026.0405\n",
      "MIN: 3\n",
      "===== 92 =====\n",
      "0 -803.1295\n",
      "1 -745.8138\n",
      "2 -700.3851\n",
      "3 -875.5954\n",
      "4 -436.1067\n",
      "MIN: 3\n",
      "===== 93 =====\n",
      "0 1388.0822\n",
      "1 1443.8303\n",
      "2 1509.0842\n",
      "3 1297.2751\n",
      "4 1843.1355\n",
      "MIN: 3\n",
      "===== 94 =====\n",
      "0 7184.1553\n",
      "1 7236.184\n",
      "2 7257.707\n",
      "3 7033.074\n",
      "4 7604.1934\n",
      "MIN: 3\n",
      "===== 95 =====\n",
      "0 2018.8658\n",
      "1 2079.086\n",
      "2 2154.372\n",
      "3 1950.6917\n",
      "4 2451.6274\n",
      "MIN: 3\n",
      "===== 96 =====\n",
      "0 -609.36835\n",
      "1 -547.70654\n",
      "2 -491.63007\n",
      "3 -708.9281\n",
      "4 -160.33667\n",
      "MIN: 3\n",
      "===== 97 =====\n",
      "0 1948.1686\n",
      "1 1992.0608\n",
      "2 1984.4554\n",
      "3 1873.494\n",
      "4 2152.1357\n",
      "MIN: 3\n",
      "===== 98 =====\n",
      "0 1119.9248\n",
      "1 1176.5393\n",
      "2 1209.3605\n",
      "3 957.42004\n",
      "4 1628.1228\n",
      "MIN: 3\n",
      "===== 99 =====\n",
      "0 -2467.5093\n",
      "1 -2417.4368\n",
      "2 -2408.9248\n",
      "3 -2526.2668\n",
      "4 -2230.9978\n",
      "MIN: 3\n"
     ]
    }
   ],
   "source": [
    "value = discriminator.predict([colorized_predictions, l_channel_imgs])\n",
    "\n",
    "for i, img in enumerate(value):\n",
    "    print('=====', i, '=====')\n",
    "    for j in range(k):\n",
    "        print(j, sum(img[:,:,j]))\n",
    "    print(\"MIN:\",np.argmin(sum(img, axis=(0,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
