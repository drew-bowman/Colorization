{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chasing Rainbows:\n",
    "## Colorizing Black and White Images with Adversarial Learning\n",
    "### Drew Bowman\n",
    "\n",
    "Adapted from [ericklindernoren](https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py)\n",
    "\n",
    "[pix2pix paper](https://arxiv.org/pdf/1611.07004.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "def sec_to_time(seconds):\n",
    "    days = seconds // (60 * 60 * 24)\n",
    "    seconds -= days * (60 * 60 * 24)\n",
    "    hours = seconds // (60 * 60)\n",
    "    seconds -= hours * (60 * 60)\n",
    "    minutes = seconds // 60\n",
    "    seconds -= minutes * 60\n",
    "    return f\"{int(days)}:{int(hours):02}:{int(minutes):02}:{int(seconds):02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Reshape, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_image_files(directory):\n",
    "    files = sorted(os.listdir(directory))\n",
    "    return [os.path.join(directory, f) for f in files if is_an_image_file(f)]\n",
    "\n",
    "def is_an_image_file(filename):\n",
    "    IMAGE_EXTENSIONS = ['.png', '.jpg', '.jpeg']\n",
    "    for ext in IMAGE_EXTENSIONS:\n",
    "        if ext in filename:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = cv2.imread(path[0])\n",
    "    \n",
    "    # Make sure all images are 256 x 256 by cropping them\n",
    "    r, c = img.shape[:2]\n",
    "    r_diff = (r - 256) // 2\n",
    "    c_diff = (c - 256) // 2\n",
    "    cropped = img[r_diff:256 + r_diff, c_diff:256 + c_diff] \n",
    "    return cropped\n",
    "\n",
    "def load_images(path, n_images=-1):\n",
    "    all_image_paths = list_image_files(path)\n",
    "    \n",
    "    if n_images < 0:\n",
    "        n_images = len(all_image_paths)\n",
    "    images_l, images_ab = [], []\n",
    "    \n",
    "    # Initialize a progress bar with max of n_images\n",
    "    pbar = tqdm_notebook(total = n_images, desc=\"Loading Images...\")\n",
    "    \n",
    "    for path in zip(all_image_paths):\n",
    "        img = load_image(path)\n",
    "        lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        lab_img = preprocess_image(lab_img)\n",
    "        \n",
    "        l = lab_img[:,:,0]\n",
    "        l = l[:,:,np.newaxis]\n",
    "        # Include all 3 channels, overwrite 1st channel with 0's\n",
    "        ab = lab_img[:,:,1:]\n",
    "\n",
    "        images_l.append(l)\n",
    "        images_ab.append(ab)\n",
    "\n",
    "        images_loaded = len(images_l)\n",
    "        \n",
    "        # Increase progress by one\n",
    "        pbar.update(1)\n",
    "        \n",
    "        if images_loaded > n_images - 1: \n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'l': np.array(images_l),\n",
    "        'ab': np.array(images_ab)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESHAPE = (256,256)\n",
    "\n",
    "def preprocess_image(cv_img):\n",
    "    img = (cv_img - 127.5) / 127.5\n",
    "    return img\n",
    "\n",
    "def deprocess_image(img):\n",
    "    img = (img * 127.5) + 127.5\n",
    "    return img.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch_from_aug(imgs):\n",
    "    final_imgs = np.zeros((imgs.shape))\n",
    "    \n",
    "    imgs = imgs.astype(np.uint8)\n",
    "    \n",
    "    for i in range(len(imgs)):\n",
    "        final_img = cv2.cvtColor(imgs[i], cv2.COLOR_RGB2LAB)\n",
    "        final_img = preprocess_image(final_img) \n",
    "        final_imgs[i] = final_img \n",
    "        \n",
    "    l_imgs = final_imgs[:,:,:,0]\n",
    "    l_imgs = np.expand_dims(l_imgs, axis=3)\n",
    "    ab_imgs = final_imgs[:,:,:,1:]\n",
    "    return l_imgs, ab_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(np_arr, path):\n",
    "    img = np_arr * 127.5 + 127.5\n",
    "    im = Image.fromarray(img)\n",
    "    im.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(truth, gray, predicted, n_to_sample, shouldSave, sample_title):\n",
    "    predicted = predicted.astype(np.float64)\n",
    "    \n",
    "    grays_merged = []\n",
    "    truth_merged = []\n",
    "    predicted_merged = []\n",
    "    for i in range(n_to_sample):\n",
    "#         newImageIndex = i * 2\n",
    "        grays_merged.append(cv2.merge((gray[i], gray[i], gray[i])))\n",
    "        truth_merged.append(cv2.merge((gray[i], truth[i])))\n",
    "        predicted_merged.append(cv2.merge((gray[i], predicted[i])))\n",
    "    \n",
    "    r = truth.shape[1]\n",
    "    c = truth.shape[2]\n",
    "\n",
    "    figure = np.zeros([r * n_to_sample + 15 * (n_to_sample-1), c * 3 + 5 * (3-1), 3], dtype=np.uint8)\n",
    "    figure += 255\n",
    "    start_r = 0\n",
    "    \n",
    "    for i in range(n_to_sample):        \n",
    "        figure[start_r:start_r + r, :c] = cv2.cvtColor(deprocess_image(truth_merged[i]), cv2.COLOR_LAB2RGB)\n",
    "        figure[start_r:start_r + r, c + 5:2*(c)+5] = deprocess_image(grays_merged[i])\n",
    "        figure[start_r:start_r + r, 2*(c+5):3*c + 5*2] = cv2.cvtColor(deprocess_image(predicted_merged[i]), cv2.COLOR_LAB2RGB)\n",
    "        start_r += r + 15\n",
    "    img = Image.fromarray(figure, \"RGB\")\n",
    "    \n",
    "    dpi = plt.rcParams['figure.dpi']\n",
    "    height, width, _ = figure.shape\n",
    "\n",
    "    preview = plt.figure(figsize=(6,4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(sample_title, fontsize = 'large')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if shouldSave:\n",
    "        figsize = width / float(dpi), height / float(dpi)\n",
    "        \n",
    "        full = plt.figure(figsize = figsize)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(sample_title, fontsize = 25)\n",
    "        plt.savefig(save_path + sample_title + \".png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_imgs_new(truth, gray, predictions, n_test_batch, shouldSave, sample_title=None, show_GT=True):    \n",
    "    # Store all merged\n",
    "    merged_predictions = []\n",
    "    merged_grays = []\n",
    "    merged_truths = []\n",
    "        \n",
    "    # For each image...\n",
    "    for i in range(n_test_batch):\n",
    "        # Get prediction, merge\n",
    "        merged = []\n",
    "        # For each k...\n",
    "        for j in range(k):\n",
    "            # Generate a prediction...\n",
    "            prediction = predictions[i,:,:,2*j:(2*j)+2].astype(np.float64)\n",
    "            # And merge it to be a 3 channel image\n",
    "            merged.append(cv2.merge((gray[i], prediction)))\n",
    "        merged_predictions.append(merged) \n",
    "        \n",
    "        # Merge the grayscale channels\n",
    "        merged_grays.append(cv2.merge((gray[i], gray[i], gray[i])))\n",
    "        \n",
    "        # Merge the l and ab to create truth\n",
    "        merged_truths.append(cv2.merge((gray[i], truth[i])))\n",
    "\n",
    "    \n",
    "    r = truth.shape[1]\n",
    "    c = truth.shape[2]\n",
    "    \n",
    "    start_r = 0\n",
    "\n",
    "    n_predictions = k\n",
    "    # Create figure\n",
    "    columns = 1 + n_predictions\n",
    "    if show_GT:\n",
    "        columns += 1\n",
    "    figure = np.zeros([r * n_test_batch + (15 * (n_test_batch-1)), (c * columns) + 5 * (columns-1), 3], dtype=np.uint8)\n",
    "    figure += 255\n",
    "    \n",
    "    # Loop through sets of test images\n",
    "    for i in range(n_test_batch):\n",
    "        # Place truth and gray\n",
    "        if show_GT:\n",
    "            figure[start_r:start_r + r, :c] = cv2.cvtColor(deprocess_image(merged_truths[i]), cv2.COLOR_LAB2RGB)\n",
    "            figure[start_r:start_r + r, c + 5:2*c + 5] = deprocess_image(merged_grays[i])\n",
    "        else:\n",
    "            figure[start_r:start_r + r, :c] = deprocess_image(merged_grays[i])\n",
    "\n",
    "\n",
    "\n",
    "        # Place multiple preditions in figure\n",
    "        for j in range(n_predictions):  \n",
    "            current_predictions = merged_predictions[i]\n",
    "            if show_GT:\n",
    "                figure[start_r:start_r + r, (2+j)*(c+5):(3+j)*c + (5*(2+j))] = \\\n",
    "                    cv2.cvtColor(deprocess_image(current_predictions[j]), cv2.COLOR_LAB2RGB)\n",
    "            else:\n",
    "                figure[start_r:start_r + r, (1+j)*(c+5):(2+j)*c + (5*(1+j))] = \\\n",
    "                    cv2.cvtColor(deprocess_image(current_predictions[j]), cv2.COLOR_LAB2RGB)\n",
    "        start_r += r + 15\n",
    "    img = Image.fromarray(figure, \"RGB\")\n",
    "\n",
    "    dpi = plt.rcParams['figure.dpi']\n",
    "    height, width, _ = figure.shape\n",
    "\n",
    "    preview = plt.figure(figsize=(6,4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    title = sample_title\n",
    "    plt.title(title, fontsize = 'large')\n",
    "    plt.show()\n",
    "\n",
    "    if shouldSave:\n",
    "        figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "        full = plt.figure(figsize = figsize)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(title, fontsize = 25)\n",
    "        plt.savefig(save_path + sample_title + \".png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(H, W, k):\n",
    "    # Inputs: height and width of the input image\n",
    "    # Returns the model, which generates the AB channels\n",
    "\n",
    "    # Pix2pix adapted from \n",
    "    # https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py\n",
    "\n",
    "    def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "        \"\"\"Layers used during downsampling\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if bn:\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "        return d\n",
    "\n",
    "    def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "        \"\"\"Layers used during upsampling\"\"\"\n",
    "        u = UpSampling2D(size=2)(layer_input)\n",
    "        u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "        if dropout_rate:\n",
    "            u = Dropout(dropout_rate)(u)\n",
    "        u = BatchNormalization(momentum=0.8)(u)\n",
    "        u = Concatenate()([u, skip_input])\n",
    "        return u\n",
    "\n",
    "    gf = 64 # Number of filters in the first layer of G\n",
    "\n",
    "    noise_in = Input(shape=(100,))\n",
    "    condition_in = Input(shape=(H, W, 1))\n",
    "    \n",
    "    # pass noise through a FC layer to get it to the right size\n",
    "    noise = Dense(H * H)(noise_in)\n",
    "\n",
    "    # reshape to be the size of an image channel\n",
    "    noise = Reshape((H, H, 1))(noise)\n",
    "    \n",
    "    # stick the (somewhat modified) noise as the second channel after\n",
    "    # the gray input. Assuming new dimension of hid will be\n",
    "    # B x 256 x 256 x 2, where B is the batch size.\n",
    "    if use_noise:\n",
    "        d0 = Concatenate(axis=-1)([condition_in, noise])\n",
    "        print(\"* * *\")\n",
    "        print(\"USING NOISE\")\n",
    "        print(\"* * *\")\n",
    "    else:\n",
    "        d0 = condition_in \n",
    "        print(\"* * *\")\n",
    "        print(\"NO NOISE\")\n",
    "        print(\"* * *\")\n",
    "        \n",
    "    # U-NET\n",
    "    # Downsampling\n",
    "    d1 = conv2d(d0, gf, bn=False)\n",
    "    d2 = conv2d(d1, gf*2)\n",
    "    d3 = conv2d(d2, gf*4)\n",
    "    d4 = conv2d(d3, gf*8)\n",
    "    d5 = conv2d(d4, gf*8)\n",
    "    d6 = conv2d(d5, gf*8)\n",
    "    d7 = conv2d(d6, gf*8)\n",
    "\n",
    "    # Upsampling\n",
    "    u1 = deconv2d(d7, d6, gf*8)\n",
    "    u2 = deconv2d(u1, d5, gf*8)\n",
    "    u3 = deconv2d(u2, d4, gf*8)\n",
    "    u4 = deconv2d(u3, d3, gf*4)\n",
    "    u5 = deconv2d(u4, d2, gf*2)\n",
    "    u6 = deconv2d(u5, d1, gf)\n",
    "\n",
    "    u7 = UpSampling2D(size=2)(u6)\n",
    "    \n",
    "    # Final 2-channel AB image with values between -1 and 1\n",
    "    img_out = Conv2D(2*k, kernel_size=4, strides=1, padding='same', activation='tanh', name='pred_ab')(u7)\n",
    "\n",
    "    # Make Model\n",
    "    model = Model(inputs=[noise_in, condition_in], outputs=img_out)\n",
    "    \n",
    "    # Show summary of layers\n",
    "    print(\"Generator Model:\")\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(H, W, k):\n",
    "    # Inputs: height and width of the input image\n",
    "    # Returns the model, which predicts real/fake\n",
    "    # over a set of spatial regions (i.e., predicts a matrix instead of a scalar).\n",
    "\n",
    "    # Pix2pix adapted from \n",
    "    # https://github.com/eriklindernoren/Keras-GAN/blob/master/pix2pix/pix2pix.py\n",
    "\n",
    "    def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "        \"\"\"Discriminator layer\"\"\"\n",
    "        d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if bn:\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "        return d\n",
    "\n",
    "    # Number of filters in the first layer of D\n",
    "    df = 64\n",
    "\n",
    "    img_in = Input(shape=(H, W, 2*k)) # AB channels\n",
    "    condition_in = Input(shape=(H, W, 1)) # L channel\n",
    "    \n",
    "    # Concat the L and AB channels\n",
    "    concat_imgs = Concatenate()([condition_in, img_in])\n",
    "\n",
    "    d1 = d_layer(concat_imgs, df, bn=False)\n",
    "    d2 = d_layer(d1, df*2)\n",
    "    d3 = d_layer(d2, df*4)\n",
    "    d4 = d_layer(d3, df*8)\n",
    "\n",
    "    # validity map is a one-channel matrix 1/16 the size of the input (halved 4 times).\n",
    "    # Each number predicts whether a region of the input is real/fake.\n",
    "    validity = Conv2D(1*k, kernel_size=4, strides=1, padding='same', name='pred_valid')(d4)\n",
    "\n",
    "    # Build Model\n",
    "    model = Model(inputs=[img_in, condition_in], outputs=validity)\n",
    "\n",
    "    # Show summary of layers\n",
    "    print(\"Disciminator Model:\")\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(tensor, nbins=10, axis=None):\n",
    "#     value_range = [tf.reduce_min(tensor), tf.reduce_max(tensor)]\n",
    "\n",
    "    value_range = [-1, 1]\n",
    "\n",
    "    if axis is None:\n",
    "        return tf.histogram_fixed_width(tensor, value_range, nbins=nbins)\n",
    "    else:\n",
    "        if not hasattr(axis, \"__len__\"):\n",
    "            axis = [axis]\n",
    "\n",
    "        other_axis = [x for x in range(0, len(tensor.shape)) if x not in axis]\n",
    "        swap = tf.transpose(tensor, [*other_axis, *axis])\n",
    "        flat = tf.reshape(swap, [-1, *np.take(tensor.shape.as_list(), axis)])\n",
    "\n",
    "        count = tf.map_fn(lambda x: tf.histogram_fixed_width(x, value_range, nbins=nbins), flat, tf.int32)\n",
    "\n",
    "        return tf.reshape(count, [*np.take([-1 if a is None else a for a in tensor.shape.as_list()], other_axis), nbins])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_k_diff(y_true, y_pred):\n",
    "    # Shape: (Batch, H, W, k, 2)\n",
    "    y_true = K.reshape(y_true, (-1, H, W, k, 2))\n",
    "    y_pred = K.reshape(y_pred, (-1, H, W, k, 2))\n",
    "\n",
    "    print(\"true:\", y_true.shape)\n",
    "    print(\"pred:\", y_pred.shape)\n",
    "\n",
    "    diff = y_true - y_pred\n",
    "    diff = K.abs(diff)\n",
    "    diff = K.mean(diff, axis=(1, 2, 4)) # mean of (H, W, 2) leaves (B, k)\n",
    "    \n",
    "    loss_metric = diff\n",
    "\n",
    "    min_for_each_batch = K.min(loss_metric, axis=1)\n",
    "    return K.sum(min_for_each_batch) #* .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_k_diff_plus_k_entropy_diff(y_true, y_pred):\n",
    "    # Shape: (Batch, H, W, k, 2)\n",
    "    y_true = K.reshape(y_true, (-1, H, W, k, 2))\n",
    "    y_pred = K.reshape(y_pred, (-1, H, W, k, 2))\n",
    "\n",
    "    diff = y_true - y_pred\n",
    "    diff = K.abs(diff)\n",
    "    diff = K.mean(diff, axis=(1, 2, 4)) # mean of (H, W, 2) leaves (B, k)\n",
    "    \n",
    "    true_hist_ab = histogram(y_true, nbins=25, axis=[1,2]) # hist of (H, W) leaves (B, k, 2, bins)\n",
    "    \n",
    "    pred_hist_ab = histogram(y_pred, nbins=25, axis=[1,2]) # hist of (H, W) leaves (B, k, 2, bins)\n",
    "    \n",
    "    true_hist_ab /= H * W\n",
    "    pred_hist_ab /= H * W\n",
    "    \n",
    "    true_hist_ab = K.clip(true_hist_ab, K.epsilon(), 1-K.epsilon())\n",
    "    pred_hist_ab = K.clip(pred_hist_ab, K.epsilon(), 1-K.epsilon())\n",
    "\n",
    "    # Sum of -plogp (entropy) across bins\n",
    "    true_hist_sum = -K.sum(true_hist_ab * K.log(true_hist_ab), axis=[3]) # sum of (bins) leaves (B, k, 2)\n",
    "    pred_hist_sum = -K.sum(pred_hist_ab * K.log(pred_hist_ab), axis=[3]) # sum of (bins) leaves (B, k, 2)\n",
    "    \n",
    "    # Take the difference of the entropies\n",
    "    diff_entropies = K.abs(true_hist_sum - pred_hist_sum)\n",
    "    \n",
    "    # Calc mean abs difference for each k\n",
    "    mad_entropies = K.mean(diff_entropies, axis=2) # mean of (B, k, 2) leaves (B, k)\n",
    "    \n",
    "    loss_metric = diff\n",
    "    best_k = K.argmin(loss_metric, axis=1)\n",
    "    \n",
    "    # Get indexes for best k\n",
    "    batch_range = K.arange(BATCH_SIZE, dtype='int64')\n",
    "    batch_range = K.reshape(batch_range, (BATCH_SIZE, 1))\n",
    "    best_k = K.reshape(best_k, (BATCH_SIZE, 1))\n",
    "    idx = K.concatenate((batch_range, best_k), axis=1)\n",
    "    \n",
    "    # Slice to get mins\n",
    "    min_for_each_n = tf.gather_nd(loss_metric, idx)\n",
    "    diff_entropy_each_n = tf.gather_nd(mad_entropies, idx)\n",
    "\n",
    "    return (K.sum(min_for_each_n) + (.01 * K.sum(K.cast(diff_entropy_each_n, dtype=\"float32\")))) #/ 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_k_chroma(y_true, y_pred):\n",
    "    # Shape: (Batch, H, W, k, 2)\n",
    "    y_true = K.reshape(y_true, (-1, H, W, k, 2))\n",
    "    y_pred = K.reshape(y_pred, (-1, H, W, k, 2))\n",
    "\n",
    "    truth_chroma = K.sum(K.square(y_true), axis=(4)) # sum of (2) squared leaves (B, H, W, k)\n",
    "    pred_chroma = K.sum(K.square(y_pred), axis=(4)) # sum of (2) squared leaves (B, H, W, k)\n",
    "    \n",
    "    sqrt_truth_chroma = K.sqrt(truth_chroma)\n",
    "    sqrt_pred_chroma = K.sqrt(pred_chroma)\n",
    "\n",
    "    diff_chroma = K.abs(truth_chroma - pred_chroma) # still (B, H, W, k)\n",
    "    \n",
    "    sum_diff_chroma = K.sum(diff_chroma, axis=(1, 2)) # Leave (B, k)\n",
    "    \n",
    "    # Add Sum of Average Differences (SAD) term\n",
    "    diff = y_true - y_pred\n",
    "    diff = K.abs(diff)\n",
    "    diff = K.mean(diff, axis=(1, 2, 4)) # mean of (H, W, 2) leaves (B, k)\n",
    "    \n",
    "    transf_sum_diff_chroma = sum_diff_chroma / 1e7 # Values between 0-10\n",
    "    transf_diff = diff / 35 / 10 # Values between 0-1\n",
    "    \n",
    "    \n",
    "    loss_metric = transf_sum_diff_chroma + transf_diff # (B, k)\n",
    "    \n",
    "    min_for_each_batch = K.min(loss_metric, axis=1) # Choose best k for each B\n",
    "    return K.sum(min_for_each_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_dist_between_chroma_preds(y_pred):\n",
    "    distances = []\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(k):\n",
    "        for j in range(i + 1, k):\n",
    "            diff = K.sum(K.square(y_pred[:, :, :, i] - y_pred[:, :, :, j]), axis=(1,2)) # (B)\n",
    "            distances.append(diff)\n",
    "            count += 1\n",
    "    stacked = K.stack(distances, axis=1) \n",
    "    print(\"Stacked:\", stacked.shape)\n",
    "    return -K.min(stacked, axis=1) # We want to maximize the distance between predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_dist_between_color_preds(y_pred):\n",
    "    # y_pred is (B, H, W, k, 2)\n",
    "    distances = []\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(k):\n",
    "        for j in range(i + 1, k):\n",
    "            diff = y_pred[:, :, :, i, :] - y_pred[:, :, :, j, :] # (B, H, W, 2)\n",
    "            sum_diff = K.sum(K.square(diff), axis=(1,2,3)) # (B)\n",
    "            distances.append(sum_diff)\n",
    "            count += 1\n",
    "    stacked = K.stack(distances, axis=1)\n",
    "    print(\"Stacked:\", stacked.shape)\n",
    "    return -K.min(stacked, axis=1) # We want to maximize the distance between predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_dist_between_hue_angles(y_pred):\n",
    "    # y_pred is (B, H, W, k, 2)\n",
    "    distances = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        for j in range(i + 1, k):\n",
    "            # https://stackoverflow.com/a/2007279\n",
    "            angle_i = tf.math.atan2(y_pred[:, :, :, i, 0], y_pred[:, :, :, i, 1])\n",
    "            angle_j = tf.math.atan2(y_pred[:, :, :, j, 0], y_pred[:, :, :, j, 1])\n",
    "            diff = tf.math.atan2(tf.math.sin(angle_i - angle_j), tf.math.cos(angle_i - angle_j)) # (B, H, W)\n",
    "            sum_diff = K.sum(K.square(diff), axis=(1,2)) # (B)\n",
    "            distances.append(sum_diff)\n",
    "    stacked = K.stack(distances, axis=1)\n",
    "    print(\"Stacked:\", stacked.shape)\n",
    "    return -K.min(stacked, axis=1) # We want to maximize the distance between predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_k_chroma_with_pairwise_difference_k(y_true, y_pred):\n",
    "    # Shape: (Batch, H, W, k, 2)\n",
    "    y_true = K.reshape(y_true, (-1, H, W, k, 2))\n",
    "    y_pred = K.reshape(y_pred, (-1, H, W, k, 2))\n",
    "\n",
    "    truth_chroma = K.sum(K.square(y_true), axis=(4)) # sum of (2) squared leaves (B, H, W, k)\n",
    "    pred_chroma = K.sum(K.square(y_pred), axis=(4)) # sum of (2) squared leaves (B, H, W, k)\n",
    "    \n",
    "    sqrt_truth_chroma = K.sqrt(truth_chroma)\n",
    "    sqrt_pred_chroma = K.sqrt(pred_chroma)\n",
    "    \n",
    "    diff_chroma = K.abs(sqrt_truth_chroma - sqrt_pred_chroma) # still (B, H, W, k)\n",
    "    \n",
    "    sum_diff_chroma = K.sum(diff_chroma, axis=(1, 2)) # Leave (B, k)\n",
    "\n",
    "    transf_sum_diff_chroma = sum_diff_chroma / 1e7 # Values between 0-10\n",
    "    \n",
    "    min_dist_hue = min_dist_between_hue_angles(y_pred) / 1e7 / 2 / 2 # Values between 0 and -10\n",
    "\n",
    "    return K.sum(transf_sum_diff_chroma) + K.sum(min_dist_hue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_k_diff_minus_k_std(y_true, y_pred):\n",
    "    # Shape: (Batch, H, W, k, 2)\n",
    "    y_true = K.reshape(y_true, (-1, H, W, k, 2))\n",
    "    y_pred = K.reshape(y_pred, (-1, H, W, k, 2))\n",
    "\n",
    "    print(\"true:\", y_true.shape)\n",
    "    print(\"pred:\", y_pred.shape)\n",
    "\n",
    "    diff = y_true - y_pred\n",
    "    diff = K.abs(diff)\n",
    "    diff = K.mean(diff, axis=(1, 2, 4))\n",
    "    std_dev = K.std(y_pred, axis=(1, 2, 4))\n",
    "    \n",
    "    loss_metric = diff - (0.05 * std_dev)\n",
    "    min_for_each_batch = K.min(loss_metric, axis=1)\n",
    "    return K.sum(min_for_each_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def generate_noise(n_samples, noise_dim):\n",
    "    X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n",
    "    return X\n",
    "\n",
    "def show_samples(batchidx, save_path):\n",
    "    fig, axs = plt.subplots(5, 6, figsize=(10,6))\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "    #fig, axs = plt.subplots(5, 6)\n",
    "    #fig.tight_layout()\n",
    "    for classlabel in range(10):\n",
    "        row = int(classlabel / 2)\n",
    "        coloffset = (classlabel % 2) * 3\n",
    "        lbls = one_hot_encode([classlabel] * 3)\n",
    "        noise = generate_noise(3, 100)\n",
    "        gen_imgs = generator.predict([noise, lbls])\n",
    "\n",
    "        for i in range(3):\n",
    "            # Dont scale the images back, let keras handle it\n",
    "            img = image.array_to_img(gen_imgs[i], scale=True)\n",
    "            axs[row,i+coloffset].imshow(img)\n",
    "            axs[row,i+coloffset].axis('off')\n",
    "            if i ==1:\n",
    "                axs[row,i+coloffset].set_title(tags[classlabel])\n",
    "    plt.savefig(save_path + '.jpg')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(g_losses, d_losses, epoch_num, scale_factor):\n",
    "    # Scale axis so it lines up with epoch_num\n",
    "    x_axis = [epoch_num * x / (len(g_losses) - 1) for x in range(len(g_losses))]\n",
    "    \n",
    "    g_scaled = [x * scale_factor for x in g_losses]\n",
    "    \n",
    "    ax = subplot(1,1,1)\n",
    "    ax.plot(x_axis, g_scaled, label=\"Generator\")\n",
    "    ax.plot(x_axis, d_losses, label=\"Discriminator\")\n",
    "    plt.title(\"Losses After \" + str(epoch_num) + \" Epochs\")\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels)\n",
    "    plt.savefig(save_path + \"Losses.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test name - used in file path, log, email notification\n",
    "test_name = \"places2_final_k_1_with_noise\"\n",
    "\n",
    "# Training parameters\n",
    "n_images = -1    # Number of images to load for training; recommended = 512\n",
    "BATCH_SIZE = 6\n",
    "N_EPOCHS = 100\n",
    "retrain = False\n",
    "use_noise = True\n",
    "\n",
    "# Weights of G / D Loss in Full Model\n",
    "'''\n",
    "The GAN learns through both a generator and discriminator loss\n",
    "Tweak weights to minimize or maximize importance of either\n",
    "Remove either loss by changing coefficient to 0\n",
    "Default G:D 100:1\n",
    "''' \n",
    "gen_loss_coeff = 100.0\n",
    "disc_loss_coeff = 1.0\n",
    "\n",
    "# Generator loss function\n",
    "gen_loss = min_k_diff\n",
    "# gen_loss = min_k_diff_plus_k_entropy_diff\n",
    "# gen_loss = min_k_chroma\n",
    "# gen_loss = min_k_diff_minus_k_std\n",
    "# gen_loss = min_k_chroma_with_pairwise_difference_k\n",
    "\n",
    "\n",
    "# Dataset\n",
    "# dataset = 'circle_pairs_equal_l_red_blue/'\n",
    "# dataset = 'circle_pairs/'\n",
    "# dataset = 'new_circles/'\n",
    "# dataset = '../Colorization_GAN/circle_pairs/'\n",
    "# dataset = 'lsun/'\n",
    "dataset = 'places2/'\n",
    "\n",
    "# Number of predictions (modes)\n",
    "k = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to store output\n",
    "generic_output_folder = \"Output/\"\n",
    "new_output_folder = test_name + \"/\"\n",
    "save_path = generic_output_folder + new_output_folder\n",
    "\n",
    "# Ensure output can save in desired location\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code couldn't handle a large training set (not enough memory)\n",
    "# Later code uses ImageDataGenerator to read in individual batches\n",
    "\n",
    "# # Get training images\n",
    "# # Load dataset, convert to LAB, normalize to range [-1, 1]\n",
    "# data = load_images(dataset + 'train', n_images)\n",
    "\n",
    "# # Separate into inputs (X) and outputs (Y)\n",
    "# y_train, X_train = data['ab'], data['l']\n",
    "\n",
    "# num_batches = X_train.shape[0] // BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample_y = y_train[4:7]\n",
    "# sample_x = X_train[4:7]\n",
    "\n",
    "# sample_images(sample_y, sample_x, sample_y, 3, False, \"Proof that images are read correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get random seed\n",
    "# seed = np.random.randint(0,1000000000)\n",
    "\n",
    "# # Augment data; ensure they're augmented the same way\n",
    "# augment_X = augment.flow(sample_x, seed=seed)[0]\n",
    "# augment_Y = augment.flow(sample_y, seed=seed)[0]\n",
    "\n",
    "# # Convert type to what it was before augmentation\n",
    "# augment_X, augment_Y = augment_X.astype(\"float64\"), augment_Y.astype(\"float64\")\n",
    "\n",
    "# # Display\n",
    "# sample_images(augment_Y, augment_X, augment_Y, 3, False, \"Proof that images are augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GAN creation\n",
    "H = W = 256\n",
    "\n",
    "# Discriminator loss - MSE seems to produce better results\n",
    "#discrim_loss = 'binary_crossentropy'\n",
    "discrim_loss = 'mse'\n",
    "\n",
    "# 1. Discriminator\n",
    "# Calculate output shape of D (PatchGAN)\n",
    "patch = H // 2**4 # Input size gets cut in half 4 times\n",
    "discriminator = get_discriminator(H, W, k)\n",
    "discriminator.name = 'discrim_model' # Need a name for the loss dictionary below\n",
    "discriminator.compile(optimizer=Adam(2e-4, 0.5), loss=discrim_loss, metrics=['accuracy'])\n",
    "discriminator.trainable = False # For the combined model we will only train the generator\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Generator\n",
    "generator = get_generator(H, W, k)\n",
    "generator.name = 'gen_model' # Need a name for the loss dictionary below\n",
    "\n",
    "# 3. GAN\n",
    "gan_noise_in = Input(shape=(100,))\n",
    "gan_condition_in = Input(shape=(H, W, 1))\n",
    "\n",
    "# By conditioning on L generate a fake version of AB\n",
    "fake_AB = generator([gan_noise_in, gan_condition_in])\n",
    "\n",
    "# Discriminator determines validity of AB images / L pairs\n",
    "print(\"fake_ab:\", fake_AB.shape)\n",
    "\n",
    "print(\"gan_condition_in:\", gan_condition_in.shape)\n",
    "\n",
    "valid = discriminator([fake_AB, gan_condition_in])\n",
    "\n",
    "losses = {'gen_model': gen_loss, # used to be 'mae'\n",
    "          'discrim_model': discrim_loss}\n",
    "loss_weights = {'gen_model': gen_loss_coeff, 'discrim_model': disc_loss_coeff}\n",
    "\n",
    "gan = Model(inputs=[gan_noise_in, gan_condition_in], outputs=[fake_AB, valid])\n",
    "gan.compile(optimizer=Adam(2e-4, 0.5), loss=losses, loss_weights=loss_weights)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights from a previous model\n",
    "\n",
    "if retrain:\n",
    "    discriminator.load_weights(\"Output/pix2pix_chroma_pairwise_diff_lsun_max_color_diff/Discriminator_Weights.h5\")\n",
    "\n",
    "    gan.load_weights(\"Output/pix2pix_chroma_pairwise_diff_lsun_max_color_diff/GAN_Weights.h5\")\n",
    "    \n",
    "    # Warn the user with printout\n",
    "    print(\"* * *\")\n",
    "    print(\"LOADING PRE-EXISTING MODEL!!!\")\n",
    "    print(\"* * *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_losses = []\n",
    "d_losses = []\n",
    "d_accuracies = []\n",
    "\n",
    "# PatchGAN loss ground truths\n",
    "true_labels = np.ones((BATCH_SIZE, patch, patch, k))\n",
    "fake_labels = np.zeros((BATCH_SIZE, patch, patch, k))\n",
    "\n",
    "for epoch in tqdm_notebook(range(N_EPOCHS), desc=\"Training GAN...\"):\n",
    "\n",
    "    cum_d_loss = 0.\n",
    "    cum_g_loss = 0.\n",
    "    cum_d_acc = 0.\n",
    "\n",
    "    pbar_message = \"Epoch \" + str(epoch + 1)\n",
    "    flow_aug_imgs = augment.flow_from_directory(directory=dataset + 'train', batch_size=BATCH_SIZE, class_mode=None)\n",
    "    num_batches = len(flow_aug_imgs)\n",
    "\n",
    "    \n",
    "    for batch_idx in tqdm_notebook(range(num_batches-1), desc=pbar_message):\n",
    "        # Random indices for training examples\n",
    "#         idx = randint(0, y_train.shape[0], BATCH_SIZE)\n",
    "\n",
    "        l_channel, ab_channel = preprocess_batch_from_aug(flow_aug_imgs[batch_idx])\n",
    "        \n",
    "        # X is L channel, Y is AB\n",
    "        # Get the next set of images to be used in this iteration and augment them\n",
    "        # Get random seed\n",
    "#         seed = np.random.randint(0,1000000000)\n",
    "        \n",
    "\n",
    "        # Augment data; ensure they're augmented the same way\n",
    "#         augment_X = augment.flow(X_train[idx], seed=seed)[0]\n",
    "#         augment_Y = augment.flow(y_train[idx], seed=seed)[0]\n",
    "\n",
    "        # Convert type to what it was before augmentation\n",
    "#         l_channel, ab_channel = augment_X.astype(\"float64\"), augment_Y.astype(\"float64\")\n",
    "        \n",
    "#         l_channel = X_train[idx]\n",
    "#         ab_channel = y_train[idx]\n",
    "\n",
    "\n",
    "        \n",
    "        ab_vis = ab_channel.copy()\n",
    "        \n",
    "        ab_channel = np.expand_dims(ab_channel, axis=3)\n",
    "        ab_channel = np.repeat(ab_channel, k, axis=3) # repeat along the newly created k axis\n",
    "        ab_channel = np.reshape(ab_channel, (-1, H, W, 2*k)) # stack the channels so things are the right shape        \n",
    "\n",
    "        noise_data = generate_noise(BATCH_SIZE, 100)\n",
    "\n",
    "        # Generate fake AB channels from L\n",
    "        fake_ab = generator.predict([noise_data, l_channel])\n",
    "\n",
    "        # Train discriminator on fake and real data\n",
    "        d_loss_fake, d_acc_fake = discriminator.train_on_batch([fake_ab, l_channel], fake_labels)\n",
    "        d_loss_true, d_acc_true = discriminator.train_on_batch([ab_channel, l_channel], true_labels)\n",
    "        d_loss = (d_loss_fake + d_loss_true) / 2\n",
    "        d_acc = (d_acc_fake + d_acc_true) / 2\n",
    "        \n",
    "        cum_d_loss += d_loss\n",
    "        cum_d_acc += d_acc\n",
    "\n",
    "        # Train generator (by way of the whole gan)\n",
    "        # Note that there are 3 losses. The first should be the\n",
    "        # weighted sum of the adversarial and L1 loss values for the batch.\n",
    "        # Ref: https://machinelearningmastery.com/how-to-implement-pix2pix-gan-models-from-scratch-with-keras/\n",
    "        g_loss, _, _ = gan.train_on_batch([noise_data, l_channel], [ab_channel, true_labels])\n",
    "        cum_g_loss += g_loss\n",
    "\n",
    "        g_losses.append(g_loss)\n",
    "        d_losses.append(d_loss)\n",
    "        d_accuracies.append(d_acc)\n",
    "\n",
    "    print('Epoch: {:04d}, Gen Loss: {:0.4f}, Discrim Loss: {:0.4f}, Discrim Acc: {:0.4f}'.format(\n",
    "        epoch+1, cum_g_loss/num_batches, cum_d_loss/num_batches, cum_d_acc/num_batches))\n",
    "    sample_title = \"Epoch \" + str(epoch+1)\n",
    "#     sample_imgs_new(ab_vis, l_channel, fake_ab, 3, True, sample_title)\n",
    "    sample_imgs_new(ab_vis, l_channel, fake_ab, 1, True, sample_title, False)\n",
    "\n",
    "\n",
    "    plot_losses(g_losses, d_losses, epoch + 1, .01)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0: \n",
    "        gan.save_weights(save_path + 'GAN_Weights_Epoch_' + str(epoch + 1) + '.h5')\n",
    "        discriminator.save_weights(save_path + 'Discriminator_Weights_Epoch_' + str(epoch + 1) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's see how the predictions look on test images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(generator, truth, gray, n_test_batch, n_predictions, shouldSave, sample_title=None):\n",
    "    # Each test image will use the same random noise to show various predictions\n",
    "    noise_arrays = generate_noise(n_test_batch, 100)\n",
    "    \n",
    "    # Store all merged\n",
    "    merged_predictions = []\n",
    "    merged_grays = []\n",
    "    merged_truths = []\n",
    "    \n",
    "    predictions = generator.predict([noise_arrays, gray[:n_test_batch]])\n",
    "    \n",
    "    # For each image...\n",
    "    for i in range(n_test_batch):\n",
    "        # Get prediction, merge\n",
    "        merged = []\n",
    "        # For each k...\n",
    "        for j in range(k):\n",
    "            # Generate a prediction...\n",
    "            prediction = predictions[i,:,:,2*j:(2*j)+1].astype(np.float64)\n",
    "            # And merge it to be a 3 channel image\n",
    "            merged.append(cv2.merge((gray[i], prediction)))\n",
    "        merged_predictions.append(merged) \n",
    "        \n",
    "        # Merge the grayscale channels\n",
    "        merged_grays.append(cv2.merge((gray[i], gray[i], gray[i])))\n",
    "        \n",
    "        # Merge the l and ab to create truth\n",
    "        merged_truths.append(cv2.merge((gray[i], truth[i])))\n",
    "\n",
    "    \n",
    "    r = truth.shape[1]\n",
    "    c = truth.shape[2]\n",
    "    \n",
    "    # Loop through sets of test images\n",
    "    for i in range(len(truth)//n_test_batch):\n",
    "        start = 3*i\n",
    "        end = start + 3\n",
    "        \n",
    "        # Create figure\n",
    "        columns = 2 + n_predictions\n",
    "        figure = np.zeros([r * n_test_batch + (15 * (n_test_batch-1)), (c * columns) + 5 * (columns-1), 3], dtype=np.uint8)\n",
    "        figure += 255\n",
    "        start_r = 0\n",
    "\n",
    "        # Place images in figure\n",
    "        for j in range(n_test_batch):  \n",
    "            figure[start_r:start_r + r, :c] = cv2.cvtColor(deprocess_image(merged_truths[start + j]), cv2.COLOR_LAB2RGB)\n",
    "            figure[start_r:start_r + r, c + 5:2*c + 5] = deprocess_image(merged_grays[start + j])\n",
    "            # Loop through and place multiple predictions\n",
    "            for pred_index in range(n_predictions):\n",
    "                current_predictions = merged_predictions[start + j]\n",
    "                figure[start_r:start_r + r, (2+pred_index)*(c+5):(3+pred_index)*c + (5*(2+pred_index))] = \\\n",
    "                    cv2.cvtColor(deprocess_image(current_predictions[pred_index]), cv2.COLOR_LAB2RGB)\n",
    "            start_r += r + 15\n",
    "        img = Image.fromarray(figure, \"RGB\")\n",
    "\n",
    "        dpi = plt.rcParams['figure.dpi']\n",
    "        height, width, _ = figure.shape\n",
    "\n",
    "        preview = plt.figure(figsize=(6,4))\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        if sample_title != None:\n",
    "            title = sample_title + \" \" + str(i+1)\n",
    "            plt.title(title, fontsize = 'large')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        if shouldSave:\n",
    "            figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "            full = plt.figure(figsize = figsize)\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(title, fontsize = 25)\n",
    "            if sample_title != None:\n",
    "                plt.savefig(save_path + sample_title + \" \" + str(i+1) + \".png\")\n",
    "            else:\n",
    "                plt.savefig(save_path + \"Test Images \" + str(i+1) + \".png\")\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# THIS CELL DISPLAYS TEST IMAGES WITH NOISE\n",
    "# =========================================\n",
    "\n",
    "# Read in some test images\n",
    "num_test_imgs = 150\n",
    "# num_test_imgs = 20\n",
    "desired_num_noise_predictions = 3\n",
    "\n",
    "data = load_images(dataset + 'test', num_test_imgs)\n",
    "\n",
    "# Separate into inputs (X) and outputs (Y)\n",
    "all_y_test, all_X_test = data['ab'], data['l']\n",
    "\n",
    "all_y_test = np.repeat(all_y_test, desired_num_noise_predictions, axis=0)\n",
    "all_X_test = np.repeat(all_X_test, desired_num_noise_predictions, axis=0)\n",
    "\n",
    "num_test_imgs *= desired_num_noise_predictions\n",
    "\n",
    "noise = generate_noise(num_test_imgs, 100)\n",
    "predictions = generator.predict([noise, all_X_test])\n",
    "\n",
    "# Only used to divide up batch, truly only one img shown\n",
    "num_to_display = 3\n",
    "\n",
    "old_k = k\n",
    "k *= desired_num_noise_predictions\n",
    "for i in range(num_test_imgs // num_to_display):\n",
    "    start = num_to_display * i\n",
    "    end = start + num_to_display\n",
    "    \n",
    "    truth_ab = all_y_test[start:end]\n",
    "    grays = all_X_test[start:end]\n",
    "    predicted_ab = predictions[start:end]\n",
    "    predicted_ab = np.concatenate((predicted_ab[:1], predicted_ab[1:2], predicted_ab[2:]), axis=-1)\n",
    "    \n",
    "    title = \"Test Images \" + str(i+1)\n",
    "    sample_imgs_new(truth_ab, grays, predicted_ab, 1, True, title)\n",
    "\n",
    "k = old_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# THIS CELL DISPLAYS TEST IMAGES WITHOUT NOISE\n",
    "# ============================================\n",
    "\n",
    "# Read in some test images\n",
    "# num_test_imgs = 150\n",
    "# num_test_imgs = 20\n",
    "\n",
    "# data = load_images(dataset + 'test', num_test_imgs)\n",
    "\n",
    "# # Separate into inputs (X) and outputs (Y)\n",
    "# all_y_test, all_X_test = data['ab'], data['l']\n",
    "\n",
    "# noise = generate_noise(num_test_imgs, 100)\n",
    "# predictions = generator.predict([noise, all_X_test])\n",
    "\n",
    "# num_to_display = 3\n",
    "# for i in range(num_test_imgs // num_to_display):\n",
    "#     start = num_to_display * i\n",
    "#     end = start + num_to_display\n",
    "    \n",
    "#     truth_ab = all_y_test[start:end]\n",
    "#     grays = all_X_test[start:end]\n",
    "#     predicted_ab = predictions[start:end]\n",
    "    \n",
    "#     title = \"Test Images \" + str(i+1)\n",
    "#     sample_imgs_new(truth_ab, grays, predicted_ab, num_to_display, True, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# THIS CELL DISPLAYS TEST IMAGES WITHOUT NOISE, WITH PLACES2 LABELS\n",
    "# =================================================================\n",
    "\n",
    "# categories = ['badlands', 'butte', 'canyon', 'cliff', 'field-wild', 'forest-broadleaf', 'forest_path', 'lake-natural', 'mountain', 'tundra']\n",
    "\n",
    "# Read in some test images\n",
    "# num_test_imgs = 15\n",
    "# data = load_images(dataset + 'test')\n",
    "\n",
    "# # Separate into inputs (X) and outputs (Y)\n",
    "# all_y_test, all_X_test = data['ab'], data['l']\n",
    "\n",
    "# imgs_per_cat = len(all_y_test) // len(categories)\n",
    "\n",
    "# for i, cat in enumerate(categories):\n",
    "#     y_test = all_y_test[i*imgs_per_cat:i*imgs_per_cat + num_test_imgs]\n",
    "#     X_test = all_X_test[i*imgs_per_cat:i*imgs_per_cat + num_test_imgs]\n",
    "    \n",
    "#     noise = generate_noise(num_test_imgs, 100)\n",
    "#     predictions = generator.predict([noise, X_test])\n",
    "\n",
    "#     num_to_display = 3\n",
    "#     for i in range(num_test_imgs // num_to_display):\n",
    "#         start = num_to_display * i\n",
    "#         end = start + num_to_display\n",
    "\n",
    "#         truth_ab = y_test[start:end]\n",
    "#         grays = X_test[start:end]\n",
    "#         predicted_ab = predictions[start:end]\n",
    "\n",
    "#         title = \"Test Images \" + cat.capitalize() + \" \" + str(i+1)\n",
    "#         sample_imgs_new(truth_ab, grays, predicted_ab, num_to_display, True, title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find how often each K was the min loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_loss(y_true, y_pred):\n",
    "    y_true = np.reshape(y_true, (-1, H, W, k, 2))\n",
    "    y_pred = np.reshape(y_pred, (-1, H, W, k, 2))\n",
    "\n",
    "    diff = y_true - y_pred\n",
    "    diff = np.abs(diff)\n",
    "    diff = np.mean(diff, axis=(1, 2, 4))\n",
    "    min_for_each_n = np.min(diff, axis=1)\n",
    "    min_k = np.argmin(diff, axis=1).item()\n",
    "\n",
    "    return np.sum(min_for_each_n), min_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed to use test data\n",
    "\n",
    "noise = generate_noise(len(all_X_test), 100)\n",
    "predictions = generator.predict([noise, all_X_test])\n",
    "\n",
    "losses = []\n",
    "k_chosen = {}\n",
    "for curr_k in range(k):\n",
    "    k_chosen[curr_k] = 0\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "    truth_ab = all_y_test[i]\n",
    "    truth_ab = np.expand_dims(truth_ab, axis=0)\n",
    "    truth_ab = np.expand_dims(truth_ab, axis=3)\n",
    "    truth_ab = np.repeat(truth_ab, k, axis=3) # repeat along the newly created k axis\n",
    "    truth_ab = np.reshape(truth_ab, (-1, H, W, 2*k)) # stack the channels so things are the right shape\n",
    "    \n",
    "    loss, curr_k = np_loss(truth_ab, prediction)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    if curr_k not in k_chosen:\n",
    "        k_chosen[curr_k] = 1\n",
    "    else:\n",
    "        k_chosen[curr_k] += 1\n",
    "    \n",
    "avg_loss = sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Writing log file...\")\n",
    "filename = save_path + \"log.txt\"\n",
    "log_file = open(filename, \"w+\")\n",
    "log_file.write(\"Test Name: \" + test_name + \"\\n\\n\")\n",
    "\n",
    "log_file.write(\"Number of Images: \" + str(n_images) + \"\\n\")\n",
    "log_file.write(\"Number of Epochs: \" + str(N_EPOCHS) + \"\\n\\n\")\n",
    "\n",
    "log_file.write(\"Elapsed Time: \" + sec_to_time(time_end-time_start) + \"\\n\\n\")\n",
    "\n",
    "log_file.write(\"Start Date: \" + datetime.datetime.fromtimestamp(time_start).strftime(\"%b %d, %Y %I:%M:%S %p\") + \"\\n\")\n",
    "log_file.write(\"End Date: \" + datetime.datetime.fromtimestamp(time_end).strftime(\"%b %d, %Y %I:%M:%S %p\\n\\n\"))\n",
    "\n",
    "log_file.write(\"K: \" + str(k) + \"\\n\")\n",
    "log_file.write(\"Avg loss: \" + str(avg_loss) + \"\\n\")\n",
    "log_file.write(\"Times K has been chosen: \")\n",
    "\n",
    "percents = [value / sum(list(map(int, k_chosen.values()))) for value in k_chosen.values()]\n",
    "for percent in percents:\n",
    "    log_file.write(str(percent) + \" \")\n",
    "log_file.close()\n",
    "print(\"Saved to \" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(k), percents)\n",
    "plt.title(\"Frequency of Each K Being the Minimized Loss\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"% Chosen\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alert that code has finished running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "\n",
    "def send_email(to_addresses, subject, message):\n",
    "    # Obfuscate login info for GitHub upload\n",
    "    creds = open(\"email_creds.txt\").read().split(\":\")\n",
    "    gmail_user = creds[0]\n",
    "    gmail_pwd = creds[1]\n",
    "\n",
    "    # Establish connection\n",
    "    smtpserver = smtplib.SMTP(\"smtp.gmail.com\",587)\n",
    "    smtpserver.ehlo()\n",
    "    smtpserver.starttls()\n",
    "    smtpserver.ehlo() # extra characters to permit edit\n",
    "\n",
    "    # Login\n",
    "    smtpserver.login(gmail_user, gmail_pwd)\n",
    "\n",
    "    # Structure email\n",
    "    header = 'To:' + ', '.join(to_addresses) + '\\n' + 'From: Automated Code Notifier\\n' + 'Subject:' + subject + ' \\n'\n",
    "    msg = header + '\\n ' + message + '\\n\\n'\n",
    "\n",
    "    # Send email\n",
    "    smtpserver.sendmail(gmail_user, to_addresses, msg)\n",
    "    \n",
    "    smtpserver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_addresses = ['dbowman3@elon.edu']\n",
    "subject = \"DONE RUNNING: \" + test_name\n",
    "message = open(filename, \"r\").read()\n",
    "\n",
    "send_email(to_addresses, subject, message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
